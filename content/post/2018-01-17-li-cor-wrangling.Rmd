---
title: Importing data from a LI-COR photosynthesis meter into R
author: Eric R. Scott
date: '2018-01-17'
slug: li-cor-wrangling
categories:
  - Research
  - Data Science
tags:
  - R
  - LI-COR
  - data-wrangling
  - regexp
  - photosynthesis
  - tidyverse
  
projects: ["bace-tea"]
draft: false

header:
  image: "headers/licor-header.png"
---
```{r message=FALSE, warning=FALSE, include=FALSE}
library(knitr)
library(DiagrammeR)
```

The [LI-6400XT](https://www.licor.com/env/products/photosynthesis/LI-6400XT/) is a portable device used to measure photosynthesis in plant leaves.  As you take measurements by pressing a button on the device, they are recorded into memory.  In order to keep track of which measurments go with which plants (or experimental treatments), there is an "add remark" option where you can enter sample information before taking measurements.

When the data are exported, you get a series of .xls files and a plain text file.  Both of these have some problems that you'll have to deal with if you want to read the data into R and use it for statistical analysis or generating reports.

```{r excel, echo=FALSE, fig.cap="Excel nightmare or text nightmare? Pick your poison.", out.width="90%"}
include_graphics("/img/licor_excel.png")
```

Both file types create some problems for easily getting the data into R:

 1. **Header information** interrupts the data table format. Fortunatly, it's mostly just information about the instrument configuration that we don't need.
 2. **Untidy handling of remarks**. Instead of remarks being in their own column, they appear in the `HHMMSS` column in the .xls files and in the `Obs` column in the .txt file! And to indicate that the row is a remark, instead of giving it an observation number in `Obs`, it just says "Remark =".
 3. **Column headers are spread over two rows**.  There is a (somewhat mysterious to me) row of "in"s and "out"s under the column headers in the .xls file.
 4. Another problem that you can't see in Fig. 1 is that I've done my **measurments in several bouts**.  This produced two .xls files and a text file with header text inbetween my two sets of measurements.
 
 At this point I had to choose between reading in the .xls files with `read_xls()` from the `readxl` package and doing some wrangling from there, or to deal with the text file, which would surely include some regular expression headaches.

For some unknown reason, `read_xls()` didn't work on these files, and I had to open them in Excel, then save them as .xlsx files and use `read_xlsx()` to get them into R.  For the sake of full automatedness, I'm going to work through the text file example here.


## Tidying up raw text
```{r flowchart, echo=FALSE, message=FALSE, warning=FALSE, fig.cap="My approach to wrangling text files generated by the LI-6400XT"}
grViz("digraph rmarkdown {
        
        graph [layout = dot, rankdir = TB, fontsize = 16]
        # node definitions with substituted label text
        node [fontname = Avenir, shape = rectangle]        
        rec1 [label = '@@1']
        rec2 [label = '@@3']
        rec3 [label = '@@5']
        rec4 [label = '@@7']

        node [fontname = Avenir, shape = oval]
        ova1 [label = '@@2']

        node [fontname = Courier, shape = oval]
        ova2 [label = '@@4']
        ova3 [label = '@@6']

        # edge definitions with the node IDs
        rec1 -> ova1 -> rec2 -> ova2 -> rec3 -> ova3 -> rec4
  }
        [1]: 'Raw text'
        [2]: 'Tidy and split'
        [3]: 'List of strings'
        [4]: 'map(list, read_tsv)'
        [5]: 'List of data frames'
        [6]: 'bind_rows()'
        [7]: 'Extract sample ID\\nfrom remarks'
")
```


My approach is to read in the raw text, tidy it up, then use `read_tsv()` to get a list of data frames. After that, I planned to combine them into one big data frame and do some more tidying to extract the sample IDs from the remarks. I'll be using functions from `stringr` to do the text tidying, and functions from various `tidyverse` packages to bring it all together into a coherent data frame.

```{r packages, message=FALSE, warning=FALSE}
library(tidyverse)
library(stringr)
```

```{r}
text.raw <- read_file("licor.txt")
```

Scrolling through the text a little reveals that, conveniently, the line `"$STARTOFDATA$"` appears between the header information and the start of the actual data. The headers themselves always begin with `"OPEN"` followed by a date.  I created regular expression patterns for these and used them to split the raw text file first into separate bouts of measurements, then into headers and data, discarding the headers.
```{r}
header_pattern <- "\"OPEN \\d\\.\\d\\.\\d"
data_pattern <- "\\$STARTOFDATA\\$"

#splits into individual bouts
raw_split <- str_split(text.raw, header_pattern, simplify = TRUE)

#splits further to separate headers from actual data
raw_split2 <- str_split(raw_split, data_pattern, simplify = FALSE)

str(raw_split2)
```
It's a little hard to see here, but now there is a list of 3 elements.  The first element contains nothing (because there is nothing before the first `header_pattern`), the other elements contain two strings---one is the header, the other is the data.  Let's get rid of the headers and the empty list element.

```{r}
#extract just the second element, the actual data
raw_split3 <- raw_split2 %>%
  map(`[`, 2) %>% #equivalent to doing raw_split2[[i]][2] for every element "i"
  flatten_chr() #converts to a vector

#remove empty elements
raw_split3 <- raw_split3[!is.na(raw_split3)]
```

## Reading in our cleaned text file

Then we can finally read in our cleaned text as a tab-separated (.tsv) file.  Here I make use of `map()` from the `purrr` package to apply `read_tsv()` to every string in our raw text vector.  `skip = 1` gets rid of that weird line of "in"s and "out"s.

```{r message=FALSE, warning=FALSE}
input <- raw_split3 %>%
  map( ~ read_tsv(
    .x,
    col_types = cols(
      .default = col_double(),
      Obs = col_character(),
      HHMMSS = col_time(format = "")
    )
  ), skip = 1)

# input.all <- bind_rows(input) #not working. Says cols are different types, but that can't be true!
input.all <- rbind(input[[1]], input[[2]])
head(input.all, 10)
```

## Extracting useful remarks

The first step is moving remarks into a `remark` column while keeping the observation numbers in the `Obs` column. I'm sure there is a more elegant way to do this, but I had recently [learned about](http://purrr.tidyverse.org/reference/safely.html) the `safely()` function from `purrr` which allows you to capture errors.  I figured I could try converting elements of the `Obs` column to integers and if it failed, I could use that as a criteria for moving to a new column.

```{r message=FALSE, warning=FALSE}
#create a "safe" version of as.integer() that returns a list of a result and error
safe_as.int <- safely(as.integer)
#returns error for text remarks, returns value for integer observation numbers

input.all <- input.all %>% 
  mutate(#create a comment column to indicate if an "Obs" is actually a remark
       comment = is.na(safe_as.int(Obs)$result), 
       #copy those remarks to the remark column
       remark = ifelse(comment == TRUE, Obs, NA),
       #remove remarks from Obs column
       Obs = ifelse(comment == FALSE, Obs, NA)) %>% 
#move the remark column the the begining
select(remark, everything()) %>% 
#remove the comment column.  We're done with it
select(-comment)
head(input.all, 10)
```

In the data frame above, you'll notice that some of the remarks are just me changing parameters of the device, while others are sample IDs (e.g. "08:43:13 c 4 a" is plot c, plant 4, leaf a).  I got lucky in my sample naming convention in that the sample IDs are relatively easily distinguishable from other remarks using regular expressions.

```{r}
#you must replace NA with the literal string "NA" so str_* functions from stringr can deal with it
input.all <- input.all %>% mutate(remark = str_replace_na(remark))

IDpattern <- "[:lower:][:blank:]\\d+[:blank:][:lower:]"
str_view(input.all$remark[1:10], IDpattern)
```

Now that I've figure out a pattern that matches the ID's I can use `str_extract()` to move them to a new `sampleID` column.
```{r}
input.all <- input.all %>%
  mutate(sampleID = str_extract(remark, IDpattern)) %>% 
  select(sampleID, everything())
head(input.all, 10)
```

## Fill down
Now, if this were Excel, you could highlight that "c 4 a" and drag the corner down to fill in all the NA's. In R, you can do exactly this with the `fill()` function from `tidyr`.

```{r}
#get rid of other remarks and fill down the sample ID column
output <- input.all %>% 
  filter(!xor(remark == "NA" , is.na(sampleID))) %>%
  fill(sampleID) %>% 
  #get rid of the rest of the remark rows
  filter(complete.cases(.)) %>% 
  #get rid of the remark column
  select(-remark)
head(output, 10)
```
And finally, we have a cleaned data frame ready for use in analyses!  You could go on to separate plot ID, plant ID and leaf ID using `separate()` from `tidyr`, and then do any necessary calculations, visualizations, and modeling with the resulting data frame.
