<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Eric R. Scott on Eric R. Scott</title>
    <link>/</link>
    <description>Recent content in Eric R. Scott on Eric R. Scott</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    <copyright>&amp;copy; 2017 Eric R. Scott</copyright>
    <lastBuildDate>Sun, 15 Oct 2017 00:00:00 -0400</lastBuildDate>
    <atom:link href="/" rel="self" type="application/rss+xml" />
    
    <item>
      <title>Differential Changes in Tea Quality as Influenced by Insect Herbivory</title>
      <link>/publication/2019-scott-book_chapter/</link>
      <pubDate>Tue, 15 Jan 2019 00:00:00 +0000</pubDate>
      
      <guid>/publication/2019-scott-book_chapter/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Combined impacts of prolonged drought and warming on plant size and foliar chemistry [in press]</title>
      <link>/publication/2019-orians-aob/</link>
      <pubDate>Wed, 07 Nov 2018 00:00:00 +0000</pubDate>
      
      <guid>/publication/2019-orians-aob/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Trip to Uji</title>
      <link>/2018/11/07/trip-to-uji/</link>
      <pubDate>Wed, 07 Nov 2018 00:00:00 +0000</pubDate>
      
      <guid>/2018/11/07/trip-to-uji/</guid>
      <description>&lt;p&gt;At the end of my &lt;a href=&#34;2018-07-20-last-fieldwork-season&#34; target=&#34;_blank&#34;&gt;last field season&lt;/a&gt;, I was lucky enough to be joined by my wife for some vacationing.  We spent about a week in China, and about a week in Kyoto, Japan, a mecca for Japanese green tea lovers.  It was &lt;em&gt;hot&lt;/em&gt; in August, and the super umami iced sencha we were offered at hotels and restaurants was a refreshing change from only hot beverages in China. Near the end of our stay, we took a day trip to Uji.  I was initially expecting Uji to be a bustling upscale downtown full of tea shops surrounded by tea gardens.  But what I heard from all our guide books was that it was mostly a tea-themed tourist trap.  Either way, I was down to experience it first-hand.&lt;/p&gt;

&lt;p&gt;On our way down, we had planned to make a stop at Inari temple, and last minute decided to first go to Fukuji temple, since it was on the way.&lt;/p&gt;

&lt;p&gt;picture of tofukuji&lt;/p&gt;

&lt;p&gt;After wandering the temple grounds at Fukuji, we decided to walk to Inari temple.  It was only about a 15 min walk, and it didn&amp;rsquo;t seem worth it to get back on the train.  We were, however, unprepared for the amount of walking necessary at Inari temple.  We knew it was famous for it&amp;rsquo;s paths covered with organge painted gateways, but we didn&amp;rsquo;t know that those paths went &lt;strong&gt;to the top of a mountain&lt;/strong&gt;. My legs were &lt;em&gt;already&lt;/em&gt; tired after our morning stroll from Fukuji compounded with almost two weeks of walking an average of 10 miles a day. Every time we thought we were making progress, we would come across a YOU ARE HERE map that made it seem like we&amp;rsquo;d never get to the top.  Then, more orange gates.&lt;/p&gt;

&lt;p&gt;Eventually, we gave up.  We think we made it almost &lt;sup&gt;3&lt;/sup&gt;&amp;frasl;&lt;sub&gt;4&lt;/sub&gt; of the way, to a spot with a very nice view.  If there was any hope of us making it to Uji with our leg muscles intact, we had to turn back.&lt;/p&gt;

&lt;p&gt;We made it to Uji and shuffled doggedly to our first stop, Kyoryouri Ujigawa, a restaurant overlooking the Uji river that I found out about from Ricardo Caicedo&amp;rsquo;s &lt;a href=&#34;https://www.myjapanesegreentea.com/uji-press-tea-tour-2016-part-3&#34; target=&#34;_blank&#34;&gt;blog post&lt;/a&gt;.  It was green tea everything!  Matcha soba, inari sushi with matcha sprinkled on top, tempura tea leaf, and of course a cup of sencha.  The restaurant is on the third floor and all tatami mats.  It was &lt;em&gt;so&lt;/em&gt; wonderful to kick off our shoes and eat some delicous food while taking in the view.  We were refreshed and ready to do some shopping!&lt;/p&gt;

&lt;p&gt;[restaurant]&lt;/p&gt;

&lt;p&gt;We headed across the river to ____ which was one of the oldest tea shops in Uji.  I had come to Uji with intentions to buy some gyokuoro&amp;mdash;the super ummami result of shading tea plants for several weeks before harvest.  I knew it would be expensive, but without any way to taste it before buying (we &lt;em&gt;were&lt;/em&gt; given a sample of some delicious sencha), we decided to move on.&lt;/p&gt;

&lt;p&gt;[pic outside of tea shop]&lt;/p&gt;

&lt;p&gt;We ended up at another bookmarked spot, _____, also extremely old and in continous operation&amp;hellip;..  Here, their tea offerings were much more accessible.  Their wall of tea was organized with separate shelves for gyokuro, sencha, and other teas such as houjicha and genmaicha.  From left to right, teas increased in quality, price, and concentration of that delicious umami tasting amino acid, L-theanine.  On the top shelf were the, well, top-shelf teas!  We were offered a sample of a mid-range gyokuro which was already &lt;strong&gt;so&lt;/strong&gt; umami that it was almost unpleasant.  Amazing stuff, but not something I&amp;rsquo;d want to drink all the time.  Eventually we decided that the good sencha was worlds better than the gyokuro we usually have access to in the US, so we picked up some sencha and some kukicha made from gyokuro stems and called it a tea shopping success.&lt;/p&gt;

&lt;p&gt;[tea shop wall of tea]&lt;/p&gt;

&lt;p&gt;Next stop, snack time!  Feeling accomplished in tea shopping, we went &lt;em&gt;back&lt;/em&gt; across the bridge to the first place we went to for delicious matcha with sweets in it!&lt;/p&gt;

&lt;p&gt;[matcha snacks]&lt;/p&gt;

&lt;p&gt;We made one final stop on the way out of town to get souvenirs.  This shop was all matcha everything.  Matcha chocolate, matcha cookies, matcha ice cream, matcha mochi, matcha cakes, and, of course, matcha.&lt;/p&gt;

&lt;p&gt;[uji mailbox shaped like a tea jar]&lt;/p&gt;

&lt;p&gt;My legs and hips hurting, we made it back to the trainstation and got some pictures with the Uji city mascott (a baby with green hair, a matcha whisk on his head, and a cape that says &amp;ldquo;tea&amp;rdquo;) and heading back to our hotel.&lt;/p&gt;

&lt;p&gt;[uji mascott]&lt;/p&gt;

&lt;p&gt;Overall, the town of Uji wasn&amp;rsquo;t what I expected or what I had heard it would be. It was a small sleepy town, which was definitely tea-themed and touristy, but not the tourist &lt;em&gt;trap&lt;/em&gt; I had been told it would be.  The matcha and matcha products I tasted were all what would be considered high-quality in the US, so even if we were getting the cheap stuff, it was some of the best I&amp;rsquo;d had.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Interactive effects of drought severity and simulated herbivory on tea (Camellia sinensis) volatile and non-volatile metabolites</title>
      <link>/publication/2018-scott-eeb/</link>
      <pubDate>Sun, 28 Oct 2018 00:00:00 +0000</pubDate>
      
      <guid>/publication/2018-scott-eeb/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Use of partial least squares regression (PLS) in ecology</title>
      <link>/project/pls-ecology/</link>
      <pubDate>Wed, 12 Sep 2018 00:00:00 +0000</pubDate>
      
      <guid>/project/pls-ecology/</guid>
      <description>&lt;p&gt;As ecology datasets become increasingly larger due to citizen science, high-throughput methods, and remote and automated data collection technology, we need better methods to analyze multivariate data. A typical approach to multivariate data in ecology is to use principal components analysis, an unsupervised technique. Unsupervised techniques like PCA attempt to explain as much &lt;em&gt;variation&lt;/em&gt; in the data as possible in fewer axes or ‘latent variables’ than there are variables in the data set. Separation in a PCA score plot (of the two axes that explain the most variation in the data) are then often used to make some conclusions about clustering of data points into separate groups, or about the effects of some explanatory variable. However, the variables that most strongly differentiate two groups, or most strongly co-vary with some explanatory variable are not necessarily the same variables loaded onto the PCA axes.&lt;/p&gt;
&lt;p&gt;Partial least squares regression (PLS, alternately ‘projection to latent structures’) is a supervised multivariate statistical technique. PLS, a supervised technique, attempts to explain &lt;em&gt;covariation&lt;/em&gt; with a explanatory variable, and it’s built with more variables than samples in mind. Because of that, it’s been warmly adopted by analytic chemists and chemical ecologists, but I believe it has applications to other fields of ecology.&lt;/p&gt;
&lt;div class=&#34;figure&#34;&gt;&lt;span id=&#34;fig:unnamed-chunk-1&#34;&gt;&lt;/span&gt;
&lt;img src=&#34;/img/PLSvsPCA.png&#34; alt=&#34;A schematic of PCA (A) compared to PLS (B).  In a PCA score plot (right), the x axis is a combination of variables (in this example, the three metabolites) that explains the most variation in the data, regardless of group membership.  PLS, on the other-hand, attempts to explain the co-variation with an explanatory variable (&#39;Treatment&#39; in this example).&#34; width=&#34;60%&#34; /&gt;
&lt;p class=&#34;caption&#34;&gt;
Figure 1: A schematic of PCA (A) compared to PLS (B). In a PCA score plot (right), the x axis is a combination of variables (in this example, the three metabolites) that explains the most variation in the data, regardless of group membership. PLS, on the other-hand, attempts to explain the co-variation with an explanatory variable (‘Treatment’ in this example).
&lt;/p&gt;
&lt;/div&gt;
&lt;p&gt;Unfortunately, researchers used to looking for visual separation in PCA score plots may be prone to misinterpreting PLS score plots because even when separation is not statistically significant, they may still show visual separation.&lt;/p&gt;
&lt;p&gt;In order to bring awareness to this algorithm and promote responsible use, I’m simulating different multivariate data scenarios using some &lt;a href=&#34;https://github.com/Aariq/chemhelper&#34;&gt;custom R functions&lt;/a&gt; to investigate it’s properties and compare its performance to other statistical methods. I’m also developing a ‘best practices’ for reporting results of PLS analyses, and finding some fun ecological and &lt;a href=&#34;http://www.ericrscott.com/2018/03/05/cupcakes-vs-muffins/&#34;&gt;non-ecological&lt;/a&gt; datasets to demonstrate its properties with.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>The importance of insect herbivore density to induced metabolite blends in tea plants (Camellia sinensis) and implications for tea quality. [1st place in section talk competition]</title>
      <link>/talk/entsoc-2018-talk/</link>
      <pubDate>Sun, 12 Aug 2018 00:00:00 +0000</pubDate>
      
      <guid>/talk/entsoc-2018-talk/</guid>
      <description></description>
    </item>
    
    <item>
      <title>[poster] Interactive effects of drought severity and herbivory on tea (Camellia sinensis) volatile and non-volatile metabolites.</title>
      <link>/talk/entsoc-2018-poster/</link>
      <pubDate>Sat, 11 Aug 2018 00:00:00 +0000</pubDate>
      
      <guid>/talk/entsoc-2018-poster/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Can pests rescue tea quality from climate change?</title>
      <link>/talk/can-pests-rescue-tea-quality/</link>
      <pubDate>Fri, 20 Jul 2018 00:00:00 +0000</pubDate>
      
      <guid>/talk/can-pests-rescue-tea-quality/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Last Fieldwork Season in China</title>
      <link>/2018/07/20/last-fieldwork-season/</link>
      <pubDate>Fri, 20 Jul 2018 00:00:00 +0000</pubDate>
      
      <guid>/2018/07/20/last-fieldwork-season/</guid>
      <description>&lt;p&gt;I’m currently in Hangzhou, China at the &lt;a href=&#34;www.tricaas.com&#34;&gt;Tea Research Institute&lt;/a&gt;(TRI) for my fourth and last time. It’s bitter sweet (like my favorite teas ;-) ) since I’m both glad to be nearing the end of my PhD, and sad to say goodbye to all the friends I’ve made and a city I’ve really grown to enjoy living in.&lt;/p&gt;
&lt;div id=&#34;fieldwork&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Fieldwork&lt;/h2&gt;
&lt;p&gt;This final summer, I’ve been focusing on a few experiments having to do with leafhoppers and their effects on tea chemistry (see the &lt;a href=&#34;/project/climate-leafhopper-quality/&#34;&gt;project page&lt;/a&gt; for more info). I’m repeating an experiment from last year, where I put different densities of insects on tea plants and measure the chemistry, but this time using two different cultivars to see if they respond differently to insect attack.&lt;/p&gt;
I’m also trying my hand at making oolong tea!
&lt;div class=&#34;figure&#34;&gt;&lt;span id=&#34;fig:unnamed-chunk-2&#34;&gt;&lt;/span&gt;
&lt;img src=&#34;/img/myoolong.jpg&#34; alt=&#34;Jin Guan Yin leaves after two rounds of gentle bruising&#34; width=&#34;60%&#34; /&gt;
&lt;p class=&#34;caption&#34;&gt;
Figure 1: Jin Guan Yin leaves after two rounds of gentle bruising
&lt;/p&gt;
&lt;/div&gt;
&lt;p&gt;This is part of an experiment aiming to better understand when leafhoppers are a pest, and when they can improve tea quality. They’re definitely considered a pest to farmers that make green tea, but prized by some farmers making &lt;a href=&#34;https://specialtyteaalliance.org/world-of-tea/oriental-beauty-bug-bitten-teas/&#34;&gt;Eastern Beauty oolong&lt;/a&gt;. There are &lt;em&gt;many&lt;/em&gt; reasons for this, but I’m curious about how tea leaves react during processing after being previously damaged by leafhoppers. I’ve written a bit about this on &lt;a href=&#34;http://www.teageek.net/blog/2018/03/oolong-mid-oxidized/&#34;&gt;TeaGeek&lt;/a&gt; before, so you can read more about what’s going on during oolong processing there.&lt;/p&gt;
&lt;p&gt;I’m doing these two experiments at TRI’s new-ish experimental field station in near-by Shengzhou.&lt;/p&gt;
&lt;div class=&#34;figure&#34;&gt;&lt;span id=&#34;fig:unnamed-chunk-3&#34;&gt;&lt;/span&gt;
&lt;img src=&#34;/img/shengzhou.jpg&#34; alt=&#34;A view of the Shengzhou TRI Exeprimental Station&#34; width=&#34;80%&#34; /&gt;
&lt;p class=&#34;caption&#34;&gt;
Figure 2: A view of the Shengzhou TRI Exeprimental Station
&lt;/p&gt;
&lt;/div&gt;
&lt;p&gt;It is rather boring there since there are hardly any other students working there, it’s in a rural area, and it has barely functioning internet. But the weather last week there was &lt;em&gt;amazing&lt;/em&gt;. It was dry! It was actually dry! In China! I’ve never been anywhere &lt;strong&gt;not&lt;/strong&gt; extremely humid in China. In fact, it felt like home (California). Hot, dry, cool breezes at night, scattered fluffy clouds—perfect. I’ve always been lucky in that whenever I’m doing really grueling, repetitive, sweaty fieldwork, it’s at least been somewhere beautiful. That really keeps me going.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;people&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;People&lt;/h2&gt;
&lt;p&gt;I’m so happy to see old friends and meet new ones! I’ve been working closely with Dr. Li Xin and his masters student, Wei Ji Peng for the past 3 years and it’s great to see them again. I’ve also made friends in other departments (it’s easy to make friends at a tea research institute when you’re a foreign tea geek!) and it’s great to see them again as well.&lt;/p&gt;
&lt;div class=&#34;figure&#34;&gt;&lt;span id=&#34;fig:unnamed-chunk-4&#34;&gt;&lt;/span&gt;
&lt;img src=&#34;/img/lixin-weijipeng.jpg&#34; alt=&#34;Wei Ji-Peng (left), me (center), and Dr. Li Xin (right) at the Shengzhou experimental station&#34; width=&#34;60%&#34; /&gt;
&lt;p class=&#34;caption&#34;&gt;
Figure 3: Wei Ji-Peng (left), me (center), and Dr. Li Xin (right) at the Shengzhou experimental station
&lt;/p&gt;
&lt;/div&gt;
&lt;p&gt;I’ve also been lucky to have a Chinese REU student working with me this summer. Her name is Guo Ming Ming, and she’s been extremely helpful in carrying out experiments, catching leafhoppers, and translating (no, even after 4 years I do not speak Mandarin well enough to do much of anything on my own).&lt;/p&gt;
&lt;div class=&#34;figure&#34;&gt;&lt;span id=&#34;fig:unnamed-chunk-5&#34;&gt;&lt;/span&gt;
&lt;img src=&#34;/img/ming-ming.jpg&#34; alt=&#34;Guo Ming-Ming, an undergraduate researcher visiting from Guangzhou for the summer&#34; width=&#34;60%&#34; /&gt;
&lt;p class=&#34;caption&#34;&gt;
Figure 4: Guo Ming-Ming, an undergraduate researcher visiting from Guangzhou for the summer
&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id=&#34;computer-work&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Computer work&lt;/h2&gt;
&lt;p&gt;Fieldwork is fun, but its far too hot to work outside for most of the day. So I usually finish my morning work before breakfast most days, and occasionally do some work in the evening. Of course there are longer days for setting up experiments, but most of the time I’m in an office. I’ve been working a lot on writing and coding for a paper about using partial least squares regression (PLS) on ecological data. I’m learning a lot in the process, and I can’t wait to share it with everyone (it might even include &lt;a href=&#34;/2018/03/05/cupcakes-vs-muffins/&#34;&gt;cupcakes vs. muffins&lt;/a&gt;!)&lt;/p&gt;
&lt;/div&gt;
</description>
    </item>
    
    <item>
      <title>Retrieve chemical retention indices from NIST with {webchem}!</title>
      <link>/2018/06/28/webchem/</link>
      <pubDate>Thu, 28 Jun 2018 00:00:00 +0000</pubDate>
      
      <guid>/2018/06/28/webchem/</guid>
      <description>&lt;p&gt;My PhD has involved learning a lot more than I expected about analytical chemistry, and as I’ve been learning, I’ve been trying my best to make my life easier by writing R functions to help me out. Some of those functions have found a loving home in the &lt;code&gt;webchem&lt;/code&gt; package, part of &lt;a href=&#34;https://ropensci.org/&#34;&gt;rOpenSci&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;Papers that use gas chromatography to separate and measure chemicals often include a table of the compounds they found along with experimental retention indices and literature retention indices. A retention index is basically a corrected retention time—the time it took for the particular chemical to make it through the gas chromatograph, an instrument designed to separate chemicals, to the detector used to identify the compound (e.g. an FID or mass spectrometer). While the retention time for a particular compound might vary from run to run or beetween labs, the retention &lt;strong&gt;index&lt;/strong&gt; should be comparable. Therefore, they are often used to help identify compounds and &lt;a href=&#34;https://webbook.nist.gov/chemistry/&#34;&gt;NIST&lt;/a&gt; maintains a database of retention indeces for researchers to refer to.&lt;/p&gt;
&lt;div class=&#34;figure&#34;&gt;&lt;span id=&#34;fig:unnamed-chunk-2&#34;&gt;&lt;/span&gt;
&lt;img src=&#34;/img/kowalsick table.png&#34; alt=&#34;An example table including literature retention indices from [Kowalsick, et al. 2014](https://doi.org/10.1016/j.chroma.2014.10.058)&#34;  /&gt;
&lt;p class=&#34;caption&#34;&gt;
Figure 1: An example table including literature retention indices from &lt;a href=&#34;https://doi.org/10.1016/j.chroma.2014.10.058&#34;&gt;Kowalsick, et al. 2014&lt;/a&gt;
&lt;/p&gt;
&lt;/div&gt;
&lt;p&gt;Producing such a table of literature retention indices for potentially hundreds of metabolites by hand can be really tedious!&lt;/p&gt;
&lt;p&gt;Enter &lt;code&gt;nist_ri()&lt;/code&gt;, a handy function I wrote to scrape retention index tables from NIST. Below, I work through an example of how you might use it. First, you need to install the latest version of &lt;code&gt;webchem&lt;/code&gt;. My function isn’t in the latest CRAN release at the time of writing this blog post, but you can install from github like so:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;devtools::install_github(&amp;quot;ropensci/webchem&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;To look up a retention index, you need a CAS identifier number for the chemical (For now, at least. Other search methods may be implemented in the future). If you don’t already have CAS numbers, you can get them using other functions in &lt;code&gt;webchem&lt;/code&gt; from chemical names or other identifier numbers.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;CASs &amp;lt;- c(&amp;quot;83-34-1&amp;quot;, &amp;quot;119-36-8&amp;quot;, &amp;quot;123-35-3&amp;quot;, &amp;quot;19700-21-1&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Load the package and take a look at the help file. You’ll see that we need to choose what type of retention index to scrape, what polarity of column, and what kind of teperature program. If you browse one of the &lt;a href=&#34;https://webbook.nist.gov/cgi/cbook.cgi?ID=C78706&amp;amp;Units=SI&amp;amp;Mask=2000#Gas-Chrom&#34;&gt;NIST sites for a compound&lt;/a&gt;, this will make more sense.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;library(webchem)
?nist_ri&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Let’s get Van Den Dool &amp;amp; Kratz (AKA “linear”) retention indeces for non-polar columns using a temperature ramp. This might take a while, depending on your internet connection and how many CAS numbers you request data for. If a certain type of retention index doesn’t exist for a compound, the function will return &lt;code&gt;NA&lt;/code&gt; for all columns but the CAS number.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;RIs &amp;lt;- nist_ri(CASs, &amp;quot;linear&amp;quot;, &amp;quot;non-polar&amp;quot;, &amp;quot;ramp&amp;quot;)
head(RIs)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##       CAS      type  phase   RI length      gas substrate diameter
## 1 83-34-1 Capillary  SPB-5 1410     60     &amp;lt;NA&amp;gt;      &amp;lt;NA&amp;gt;     0.32
## 2 83-34-1 Capillary DB-5MS 1380     30   Helium      &amp;lt;NA&amp;gt;     0.25
## 3 83-34-1 Capillary  SE-54 1410     50   Helium      &amp;lt;NA&amp;gt;     0.32
## 4 83-34-1 Capillary   DB-5 1381     30 Hydrogen      &amp;lt;NA&amp;gt;     0.25
## 5 83-34-1 Capillary   DB-5 1389     30 Nitrogen      &amp;lt;NA&amp;gt;     0.25
## 6 83-34-1 Capillary DB-5MS 1399     30     &amp;lt;NA&amp;gt;      &amp;lt;NA&amp;gt;     0.25
##   thickness temp_start temp_end temp_rate hold_start hold_end
## 1      1.00         40      230         3          2       10
## 2      0.25         35      225        10          5       25
## 3        NA         40      240         8          2        5
## 4      0.25         35      270         5         NA       20
## 5      0.25         30      250         3          2        2
## 6      0.25         40      200        10          3       20
##                               reference comment
## 1                 Engel and Ratel, 2007 MSDC-RI
## 2   Lozano P.R., Drake M., et al., 2007 MSDC-RI
## 3    Schlutt B., Moran N., et al., 2007 MSDC-RI
## 4            Alves, Pinto, et al., 2005 MSDC-RI
## 5 Colahan-Sederstrom and Peterson, 2005 MSDC-RI
## 6  Whetstine, Cadwallader, et al., 2005 MSDC-RI&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;You can see there are multiple retention indices (&lt;code&gt;RI&lt;/code&gt;) for each CAS number. Let’s filter this down some more using some functions from &lt;code&gt;dplyr&lt;/code&gt; and &lt;code&gt;stringr&lt;/code&gt;.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;library(dplyr)
library(stringr)
RIs_filtered &amp;lt;- RIs %&amp;gt;%
  filter(gas == &amp;quot;Helium&amp;quot;,
         between(length, 20, 30),
         str_detect(phase, &amp;quot;5&amp;quot;),
         diameter &amp;lt; 0.3,
         thickness == 0.25)
head(RIs_filtered)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##        CAS      type  phase     RI length    gas substrate diameter
## 1  83-34-1 Capillary DB-5MS 1380.0     30 Helium      &amp;lt;NA&amp;gt;     0.25
## 2  83-34-1 Capillary DB-5MS 1396.0     30 Helium      &amp;lt;NA&amp;gt;     0.25
## 3  83-34-1 Capillary   DB-5 1391.0     30 Helium      &amp;lt;NA&amp;gt;     0.26
## 4 119-36-8 Capillary   DB-5 1201.0     25 Helium      &amp;lt;NA&amp;gt;     0.25
## 5 119-36-8 Capillary HP-5MS 1200.7     30 Helium      &amp;lt;NA&amp;gt;     0.25
## 6 119-36-8 Capillary HP-5MS 1190.0     30 Helium      &amp;lt;NA&amp;gt;     0.25
##   thickness temp_start temp_end temp_rate hold_start hold_end
## 1      0.25         35      225        10          5       25
## 2      0.25         35      200        10          5       30
## 3      0.25         50      300         6          4       20
## 4      0.25         60      200         2         NA       60
## 5      0.25         80      300         4         NA       NA
## 6      0.25         60      280         4          5       NA
##                                 reference comment
## 1     Lozano P.R., Drake M., et al., 2007 MSDC-RI
## 2 Karagül-Yüceer, Vlahovich, et al., 2003 MSDC-RI
## 3                Rostad and Pereira, 1986 MSDC-RI
## 4                 Rout, Rao, et al., 2007 MSDC-RI
## 5                Zeng, Zhao, et al., 2007 MSDC-RI
## 6         Saroglou, Dorizas, et al., 2006 MSDC-RI&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Now we could &lt;code&gt;summarise&lt;/code&gt; to get an average of all the database entries…&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;RIs_filtered %&amp;gt;% 
  group_by(CAS) %&amp;gt;% 
  summarise(mean_RI = mean(RI))&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## # A tibble: 4 x 2
##   CAS        mean_RI
##   &amp;lt;chr&amp;gt;        &amp;lt;dbl&amp;gt;
## 1 119-36-8     1193.
## 2 123-35-3      990.
## 3 19700-21-1   1430 
## 4 83-34-1      1389&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Or if we wanted to pick a single entry for each CAS number with the median RI, we could do that as well.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;best_RIs &amp;lt;- RIs_filtered %&amp;gt;%
  group_by(CAS) %&amp;gt;% 
  filter(RI == median(RI)) %&amp;gt;% 
  filter(row_number() == 1) %&amp;gt;% 
  select(CAS, RI, reference)
best_RIs&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## # A tibble: 4 x 3
## # Groups:   CAS [4]
##   CAS           RI reference                             
##   &amp;lt;chr&amp;gt;      &amp;lt;dbl&amp;gt; &amp;lt;chr&amp;gt;                                 
## 1 83-34-1     1391 Rostad and Pereira, 1986              
## 2 119-36-8    1191 Aligiannis, Kalpoutzakis, et al., 2004
## 3 123-35-3     991 Maccioni, Baldini, et al., 2007       
## 4 19700-21-1  1430 Dickschat, Wenzel, et al., 2004&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;You could then easily take this table and &lt;code&gt;*_join()&lt;/code&gt; it to your GC/MS data, if you have a column for CAS#, and select the &lt;code&gt;RI&lt;/code&gt; and &lt;code&gt;reference&lt;/code&gt; columns, for example.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;fake.data &amp;lt;- data.frame(CAS = CASs,
                 #Name = cts_convert(CASs, from = &amp;quot;CAS&amp;quot;, to = &amp;quot;Chemical Name&amp;quot;, first = TRUE),
                 Name = c(&amp;quot;skatole&amp;quot;, &amp;quot;methyl salicylate&amp;quot;, &amp;quot;beta-myrcene&amp;quot;, &amp;quot;geosmin&amp;quot;),
                 group_1_conc = round(abs(rnorm(4)), 3),
                 group_2_conc = round(abs(rnorm(4)), 3))

left_join(fake.data, best_RIs) %&amp;gt;%
  select(CAS, Name, RI, everything()) %&amp;gt;% 
  arrange(RI) %&amp;gt;%
  knitr::kable()&lt;/code&gt;&lt;/pre&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr class=&#34;header&#34;&gt;
&lt;th align=&#34;left&#34;&gt;CAS&lt;/th&gt;
&lt;th align=&#34;left&#34;&gt;Name&lt;/th&gt;
&lt;th align=&#34;right&#34;&gt;RI&lt;/th&gt;
&lt;th align=&#34;right&#34;&gt;group_1_conc&lt;/th&gt;
&lt;th align=&#34;right&#34;&gt;group_2_conc&lt;/th&gt;
&lt;th align=&#34;left&#34;&gt;reference&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td align=&#34;left&#34;&gt;123-35-3&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;beta-myrcene&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;991&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0.905&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0.503&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;Maccioni, Baldini, et al., 2007&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td align=&#34;left&#34;&gt;119-36-8&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;methyl salicylate&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;1191&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0.554&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0.799&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;Aligiannis, Kalpoutzakis, et al., 2004&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td align=&#34;left&#34;&gt;83-34-1&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;skatole&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;1391&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0.752&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;1.619&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;Rostad and Pereira, 1986&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td align=&#34;left&#34;&gt;19700-21-1&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;geosmin&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;1430&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;1.270&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0.784&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;Dickschat, Wenzel, et al., 2004&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
</description>
    </item>
    
    <item>
      <title>Striking changes in tea metabolites due to elevational effects</title>
      <link>/publication/2018-kfoury-food_chemistry/</link>
      <pubDate>Thu, 10 May 2018 00:00:00 +0000</pubDate>
      
      <guid>/publication/2018-kfoury-food_chemistry/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Python is Weird (an unabashedly biased intro to Python for R users)</title>
      <link>/2018/05/03/python-is-weird/</link>
      <pubDate>Thu, 03 May 2018 00:00:00 +0000</pubDate>
      
      <guid>/2018/05/03/python-is-weird/</guid>
      <description>

&lt;p&gt;Last semester I took a class that used Python. It was my first time really seriously using any programing language other than R. The students were about half engineers and half biologists.  The vast majority of the biologists knew R to varying degrees, but had no experience with Python, and the engineers seemed to generally have some experience with Python, or at least with languages more similar to it than R. I wish that the instructor could have taught every Python lecture like &amp;ldquo;Ok, today we&amp;rsquo;re going to learn the Python equivalent of doing ____ in R&amp;rdquo;, but of course that wouldn&amp;rsquo;t be fair to about half the students.&lt;/p&gt;

&lt;p&gt;So for anyone else making the leap from R to Python, here are three things that are going to feel really weird about Python.&lt;/p&gt;

&lt;h1 id=&#34;1-indexing-is-not-intuitive-in-python&#34;&gt;1. Indexing is not intuitive in Python&lt;/h1&gt;

&lt;p&gt;Let me just show you first and see if you can figure out what is going on:&lt;/p&gt;

&lt;p&gt;&lt;em&gt;R Code:&lt;/em&gt;&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;# R
x = c(10, 20, 30, 40, 50)
x[1]
x[1:3]
x[4:5]
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;## [1] 10
## [1] 10 20 30
## [1] 40 50
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Cool, cool.&lt;/p&gt;

&lt;p&gt;&lt;em&gt;Equivalent in Python:&lt;/em&gt;&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;# Python
x = [10, 20, 30, 40, 50]
print(x[1])
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;## 20
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;print(x[0])
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;## 10
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;print(x[3:4])
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;## [40]
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;print(x[3:5])
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;## [40, 50]
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Wait, what? Two things are really weird about this.  First, the first position in the vector is not position 1, it is position 0.  Second, &lt;code&gt;x[3:4]&lt;/code&gt; returns only a single number.  Why?!  Because in Python, the second number in the index is not inclusive, so if you want to get the 4th and 5th values of &lt;code&gt;x&lt;/code&gt; (index positions 3 and 4 in Python world), then you have to use &lt;code&gt;x[3:5]&lt;/code&gt; &lt;strong&gt;even though there is NO POSITION 5&lt;/strong&gt;.  Terrible.&lt;/p&gt;

&lt;p&gt;&lt;em&gt;Weird thing 1.1: Python is much more geared toward writing programs than R.  That means you can&amp;rsquo;t really run python code one line at a time like R and you have to explicitly &lt;code&gt;print()&lt;/code&gt; things that you want to be output to the screen.&lt;/em&gt;&lt;/p&gt;

&lt;h1 id=&#34;2-you-need-to-load-a-package-just-to-do-vector-math&#34;&gt;2. You need to load a package just to do vector math&lt;/h1&gt;

&lt;p&gt;R is built for doing math and statistics, so vectors and matrices are built in and you can do math on them!&lt;/p&gt;

&lt;p&gt;&lt;em&gt;R Code:&lt;/em&gt;&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;# R
x = c(1, 2, 3)
x + 10
x * 2
y = c(5, 6, 7)
x + y
#Yay vector arithmetic!
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;## [1] 11 12 13
## [1] 2 4 6
## [1]  6  8 10
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Python is &lt;strong&gt;not&lt;/strong&gt; built with math and statistics in mind, and this doesn&amp;rsquo;t work without using a package.&lt;/p&gt;

&lt;p&gt;&lt;em&gt;Equivalent in Python:&lt;/em&gt;&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;# Python
x = [1, 2, 3]
print(x + [10]) 
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;## [1, 2, 3, 10]
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;print(x*3) 
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;## [1, 2, 3, 1, 2, 3, 1, 2, 3]
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;y = [5, 6, 7]
print(x + y) 
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;## [1, 2, 3, 5, 6, 7]
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Clearly &lt;code&gt;+&lt;/code&gt; is doing something different in base Python&amp;mdash;it&amp;rsquo;s concatenating &lt;code&gt;x&lt;/code&gt; and &lt;code&gt;10&lt;/code&gt;.  Similarly, &lt;code&gt;*&lt;/code&gt; is not multiplying, but concatenating three &lt;code&gt;x&lt;/code&gt;s in a row. This is completely ridiculous behavior for numbers, but when you&amp;rsquo;re working with strings, it&amp;rsquo;s actually pretty freakin&amp;rsquo; great.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;# Python
print((&amp;quot;Yay &amp;quot;+&amp;quot;Python! &amp;quot;) * 5)
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;## Yay Python! Yay Python! Yay Python! Yay Python! Yay Python!
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;If you want numerical vectors to work like they should, you have to use a special kind of vector called a &lt;strong&gt;numpy array&lt;/strong&gt;.  Numpy is a package for Python that provides a bunch of functions that work on numbers.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;# Python
import numpy as np
x = np.array([1, 2, 3])
print(x + 10)
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;## [11 12 13]
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;print(x * 2) 
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;## [2 4 6]
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;y = np.array([5, 6, 7])
print(x + y)
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;## [ 6  8 10]
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;If you do math to numpy arrays, you get what you&amp;rsquo;d expect as an R user.&lt;/p&gt;

&lt;p&gt;&lt;em&gt;Wierd thing 2.1: note that the &lt;code&gt;packagename.function()&lt;/code&gt; form is equivalent to &lt;code&gt;packagename::function()&lt;/code&gt; in R, but unlike R, it is always required.  That is, as far as I know, there is nothing you can do to make &lt;code&gt;array([1,2,3])&lt;/code&gt; work without the preceding &lt;code&gt;np.&lt;/code&gt;&lt;/em&gt;&lt;/p&gt;

&lt;h1 id=&#34;3-default-assignment-behavior-is-aliasing&#34;&gt;3. Default assignment behavior is aliasing&lt;/h1&gt;

&lt;p&gt;I&amp;rsquo;m still trying to wrap my mind around this one, so rather than trying to explain it, let me show you an example first:&lt;/p&gt;

&lt;p&gt;&lt;em&gt;R Code:&lt;/em&gt;&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;# R
a1 = c(1,2,3)
a2 = a1
a2[1] = 100
a1
a2
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;## [1] 1 2 3
## [1] 100   2   3
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;code&gt;a1&lt;/code&gt; is, of course, unchanged by changing a value in &lt;code&gt;a2&lt;/code&gt;.  Let&amp;rsquo;s see if that&amp;rsquo;s true in Python.&lt;/p&gt;

&lt;p&gt;&lt;em&gt;Equivalent in Python:&lt;/em&gt;&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;# Python
import numpy as np
a1 = np.array([1,2,3])
a2 = a1
a2[1] = 100
print(a1)
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;## [  1 100   3]
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;print(a2)
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;## [  1 100   3]
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Changing a value in &lt;code&gt;a2&lt;/code&gt; &lt;em&gt;changes&lt;/em&gt; the same value in &lt;code&gt;a1&lt;/code&gt;! In this case, &lt;code&gt;a2&lt;/code&gt; is an &lt;em&gt;alias&lt;/em&gt; of &lt;code&gt;a1&lt;/code&gt;, not a copy. This only happens when you do &lt;code&gt;object1 = object2&lt;/code&gt; and not when you do something to &lt;code&gt;object2&lt;/code&gt; as you&amp;rsquo;re assigning it. Here&amp;rsquo;s another example:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;# Python
import numpy as np
a1 = np.array([1,2,3])
a2 = a1 + 2
a2[1] = 100
print(a1)
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;## [1 2 3]
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;print(a2)
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;## [  3 100   5]
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Now &lt;code&gt;a2&lt;/code&gt; is a separate object from &lt;code&gt;a1&lt;/code&gt; instead of just an alias. If you want to make an &lt;em&gt;exact&lt;/em&gt; copy, you have to do that explicitly with &lt;code&gt;a2 = np.copy(a1)&lt;/code&gt; or &lt;code&gt;a2 = a1[:]&lt;/code&gt;&lt;/p&gt;

&lt;h1 id=&#34;try-python&#34;&gt;Try Python!&lt;/h1&gt;

&lt;p&gt;As many people in the data science world have pointed out, it&amp;rsquo;s not R vs. Python, it&amp;rsquo;s &lt;a href=&#34;https://www.datasciencecentral.com/profiles/blogs/r-vs-python-r-and-python-and-something-else&#34; target=&#34;_blank&#34;&gt;R &lt;em&gt;and&lt;/em&gt; Python&lt;/a&gt;. From my limited experience, the benefits of Python over R I&amp;rsquo;ve are that it seems to be faster, defining classes and functions seems less painful, and it&amp;rsquo;s great at working with strings out of the box. I don&amp;rsquo;t really plan on working in Python more unless I have to, but knowing a bit of the language will be useful for talking shop with people who use it!&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>PhDrinking Podcast</title>
      <link>/2018/05/01/phdrinking-podcast/</link>
      <pubDate>Tue, 01 May 2018 00:00:00 +0000</pubDate>
      
      <guid>/2018/05/01/phdrinking-podcast/</guid>
      <description>&lt;p&gt;I had the wonderful opportunity to be on Sadie Wit&amp;rsquo;s &lt;a href=&#34;https://soundcloud.com/phdrinking&#34; target=&#34;_blank&#34;&gt;PhDrinking podcast&lt;/a&gt;.  Check out the episode &lt;a href=&#34;https://soundcloud.com/phdrinking/tea-totaling&#34; target=&#34;_blank&#34;&gt;here&lt;/a&gt; and subscribe to PhDrinking wherever great podcasts are casted.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Cupcake Update</title>
      <link>/2018/04/10/cupcake-update/</link>
      <pubDate>Tue, 10 Apr 2018 00:00:00 +0000</pubDate>
      
      <guid>/2018/04/10/cupcake-update/</guid>
      <description>&lt;p&gt;I know you&amp;rsquo;re all waiting on the edge of your seats for an update on the &lt;a href=&#34;http://www.ericrscott.com/2018/03/05/cupcakes-vs-muffins/&#34; target=&#34;_blank&#34;&gt;cupcakes vs. muffins data science project&lt;/a&gt;, but unfortunately I don&amp;rsquo;t have any answers to that age-old question* yet.&lt;/p&gt;

&lt;p&gt;As silly as it may sound, I&amp;rsquo;m actually considering using this data set for a paper about using PLS (partial least squares regression) for ecological data. So for now, I&amp;rsquo;m holding off on blogging about any results of analyses in case I end up wanting to use them for the publication. In the meantime, the fully cleaned (I hope) &lt;a href=&#34;https://github.com/Aariq/cupcakes-vs-muffins&#34; target=&#34;_blank&#34;&gt;dataset is up on github&lt;/a&gt;, so feel free to play around with it. Once I have a general outline for this paper, I may feel more comfortable blogging about the results. Please comment if you think I&amp;rsquo;m being silly and overparanoid about holding back on this.&lt;/p&gt;

&lt;p&gt;*all I can say is muffins probably differ from cupcakes by more than just frosting, based on the ingredients.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Cupcakes vs. Muffins</title>
      <link>/2018/03/05/cupcakes-vs-muffins/</link>
      <pubDate>Mon, 05 Mar 2018 00:00:00 +0000</pubDate>
      
      <guid>/2018/03/05/cupcakes-vs-muffins/</guid>
      <description>&lt;p&gt;One thing I’ve learned from my PhD at Tufts is that I really enjoy working data wrangling, visualization, and statistics in R. I enjoy it so much, that lately I’ve been strongly considering a career in data science after graduation. As a way to showcase my data science skills, I’ve been working on a side project to use webscraping and multivariate statistics to answer the age old question: Are cupcakes really &lt;em&gt;that&lt;/em&gt; different from muffins?&lt;/p&gt;
&lt;p&gt;Honestly, I can’t even quite remember how this idea came to me, but it started in a discussion with Dr. Elizabeth Crone about why more ecologists don’t use a statistical technique called &lt;a href=&#34;https://en.wikipedia.org/wiki/Partial_least_squares_regression&#34;&gt;partial least squares regression&lt;/a&gt;. We wanted a fun multivariate data set that could illustrate the different conclusions you might get depending on the statistical method you use. Around the same time, I came across a blog post by &lt;a href=&#34;https://aczane.netlify.com/2018/02/08/the-first-and-namesake-post-is-it-cake/&#34;&gt;@lariebyrd&lt;/a&gt; explaining machine learning using cake emoji. And that somehow led to me webscraping &lt;strong&gt;every single muffin and cupcake recipe&lt;/strong&gt; on allrecipes.com.&lt;/p&gt;
&lt;p&gt;I just finished the webscraping bit of the project this weekend. I’m not going to reproduce the code here, but rather address some of the challenges I faced, and some things I’ve learned so far. You can check out my R notebook and a .rds file of all the recipes &lt;a href=&#34;https://github.com/Aariq/cupcakes-vs-muffins&#34;&gt;over on github&lt;/a&gt;&lt;/p&gt;
&lt;div id=&#34;getting-started-on-webscraping&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;Getting started on webscraping&lt;/h1&gt;
&lt;p&gt;I followed this &lt;a href=&#34;https://towardsdatascience.com/web-scraping-tutorial-in-r-5e71fd107f32&#34;&gt;wonderful tutorial&lt;/a&gt; from José Roberto Ayala Solares to get going. Necessary tools include the &lt;code&gt;tidyverse&lt;/code&gt;, the &lt;code&gt;rvest&lt;/code&gt; package for webscraping, and a chrome plugin called &lt;a href=&#34;http://selectorgadget.com/&#34;&gt;SelectorGadget&lt;/a&gt;. Going through the example in the tutorial was really helpful for getting a hang of what is and isn’t easy/possible.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;choosing-a-data-source&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;Choosing a data source&lt;/h1&gt;
&lt;p&gt;I specifically chose allrecipes.com over, say geniuskitchen.com (an excellent recipe site) because of the way it categorizes and structures recipes. When I search “cupcake” on geniuskitchen.com, I get 1830 results (yay!), but a bunch of them are links to videos, articles, reviews, blog posts, food porn albums, and other things that are &lt;strong&gt;not&lt;/strong&gt; recipes (boo!). Allrecipes.com, on the other hand, gives me the following URL: &lt;a href=&#34;https://www.allrecipes.com/recipes/377/desserts/cakes/cupcakes/&#34; class=&#34;uri&#34;&gt;https://www.allrecipes.com/recipes/377/desserts/cakes/cupcakes/&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;This is &lt;strong&gt;ALL THE CUPCAKES&lt;/strong&gt;. From there, I played around with SelectorGadget to make sure it was going to be easy to drill down to just the links to the actual recipes, and yes, it was.&lt;/p&gt;
&lt;div class=&#34;figure&#34;&gt;&lt;span id=&#34;fig:selector-gadget&#34;&gt;&lt;/span&gt;
&lt;img src=&#34;/img/selector-gadget.png&#34; alt=&#34;SelectorGadget in action&#34;  /&gt;
&lt;p class=&#34;caption&#34;&gt;
Figure 1: SelectorGadget in action
&lt;/p&gt;
&lt;/div&gt;
&lt;p&gt;I also checked that the ingredients list of each recipe was going to be easy to scrape. They all have the same format, and some brief testing convinced me that I’d be able to figure out how to pull out ingredients.&lt;/p&gt;
&lt;p&gt;The takeaway is that for this project I had my choice of many websites, but I specifically picked one that would make my life easier because of its html structure.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;dont-scrape-too-fast&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;Don’t scrape too fast!&lt;/h1&gt;
&lt;div id=&#34;sys.sleep-is-your-friend&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;(&lt;code&gt;Sys.sleep()&lt;/code&gt; is your friend)&lt;/h2&gt;
&lt;p&gt;So once I figured out how to pull in all the links to all the cupcake recipes, I started scraping ingredients from a small sample of them. After a few debugging runs, allrecipes.com stopped responding and I just kept getting error messages. After pulling my hair out trying to figure out how I broke my code, I realized that my IP was being blocked! Because of the speed of accessing the website or how many links I accessed, my IP was suspected of being a bot or something and was temporarily (&lt;em&gt;whew&lt;/em&gt;) blocked. I turned to twitter and was reccomended an easy fix—create a custom &lt;code&gt;read_html_slow()&lt;/code&gt; function that included &lt;code&gt;Sys.sleep(5)&lt;/code&gt; which just makes R wait 5 seconds in between reading websites.&lt;/p&gt;
&lt;blockquote class=&#34;twitter-tweet&#34;&gt;&lt;p lang=&#34;en&#34; dir=&#34;ltr&#34;&gt;Make your own function with read_html followed by Sys.sleep(5) and then map using that?&lt;/p&gt;&amp;mdash; Sharon Machlis (@sharon000) &lt;a href=&#34;https://twitter.com/sharon000/status/965808697346789378?ref_src=twsrc%5Etfw&#34;&gt;February 20, 2018&lt;/a&gt;&lt;/blockquote&gt;
&lt;script async src=&#34;https://platform.twitter.com/widgets.js&#34; charset=&#34;utf-8&#34;&gt;&lt;/script&gt;

&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;library(rvest)
read_html_slow &amp;lt;- function(x, ...){
  output &amp;lt;- read_html(x)
  Sys.sleep(5) #wait 5 seconds before returning output
  return(output)
}&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id=&#34;create-your-own-custom-helper-functions&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;Create your own custom helper functions&lt;/h1&gt;
&lt;p&gt;A great side-effect of creating your own functions like &lt;code&gt;read_html_slow()&lt;/code&gt; is making your code more readable. Instead of a for-loop that calls &lt;code&gt;Sys.sleep(5)&lt;/code&gt; after every iteration of &lt;code&gt;read_html()&lt;/code&gt;, I now have one function that does it all and can be easily used in conjunction with &lt;code&gt;map()&lt;/code&gt; from the &lt;code&gt;purrr&lt;/code&gt; package.&lt;/p&gt;
&lt;p&gt;My &lt;code&gt;read_html_slow()&lt;/code&gt; function would still occasionally encounter errors like when it would encounter a broken URL. When reading in a whole list of URLs, one broken URL would mess up the whole list. I ended up expanding on &lt;code&gt;read_html_slow()&lt;/code&gt; to make &lt;code&gt;read_html_safely()&lt;/code&gt; which would output an &lt;code&gt;NA&lt;/code&gt; rather than throwing an error if a URL was broken.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;library(purrr)
read_html_safely &amp;lt;- possibly(read_html_slow, NA) #from the purrr package&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;I also created a &lt;code&gt;str_detect_any()&lt;/code&gt; which allows you to check if a string is matched by any of a vector of regular expressions. I show how I use this in the next section&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;library(stringi)
str_detect_any &amp;lt;- function(string, pattern){
  map_lgl(string, ~stri_detect_regex(., pattern) %&amp;gt;% any(.)) 
  #map_lgl is from purrr, stri_detect() is from stringi
}&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;div id=&#34;work-on-random-samples&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;Work on random samples&lt;/h1&gt;
&lt;p&gt;There were something like 200 cupcake recipes and another 100 muffin recipes on allrecipes.com, which takes a long time to read in. Rather than working on the whole data set, I used &lt;code&gt;sample()&lt;/code&gt; on my vector of recipe URLs to take a manageable sample of recipes to work on. After working through a few different random subsets, I reached a point where I was happy with how my code was working. Only then did I read in the entire data set.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;webscraped-data-is-messy&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;Webscraped data is messy&lt;/h1&gt;
&lt;div id=&#34;people-make-weird-baked-goods&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;(People make weird baked goods)&lt;/h2&gt;
&lt;p&gt;Once I had all my ingredients for muffins and cupcakes in a data frame, I needed to standardize the ingredients. For example “8 tablespoons butter, melted” and “1/2 cup unsalted, organic, non-GMO, gluten-free, single-origin butter” both needed to get converted to “1/2 cup butter.” This is where the combination of &lt;code&gt;mutate()&lt;/code&gt;, &lt;code&gt;case_when()&lt;/code&gt; and &lt;code&gt;str_detect()&lt;/code&gt; really came in handy to make readable, debuggable code.&lt;/p&gt;
&lt;p&gt;&lt;code&gt;mutate()&lt;/code&gt; is a function from the &lt;code&gt;dplyr&lt;/code&gt; package (part of &lt;code&gt;tidyverse&lt;/code&gt;) for adding new columns to data frames based on information in other columns. Here, I used it to take the ingredient descriptions and turn them into short, concise ingredients. &lt;code&gt;str_detect()&lt;/code&gt; is from the &lt;code&gt;stringr&lt;/code&gt; package and takes a string and a regular expression pattern and outputs &lt;code&gt;TRUE&lt;/code&gt; or &lt;code&gt;FALSE&lt;/code&gt;. Finally, &lt;code&gt;case_when()&lt;/code&gt; is also from &lt;code&gt;dplyr&lt;/code&gt; and provides a readable alternative to insane nested &lt;code&gt;ifelse()&lt;/code&gt; statements. For example:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;library(tidyverse)
df &amp;lt;- tibble(description = c(&amp;quot;1/2 cup unsalted, organic, non-GMO, gluten-free, single-origin butter&amp;quot;,
                             &amp;quot;1 cup buttermilk&amp;quot;,
                             &amp;quot;4 cups sugar&amp;quot;,
                             &amp;quot;4 cups slivered almonds&amp;quot;,
                             &amp;quot;1/2 cup chopped walnuts&amp;quot;,
                             &amp;quot;1 teaspoon salt&amp;quot;,
                             &amp;quot;25 blueberries&amp;quot;))

#all nuts should match one of these patterns
nuts &amp;lt;- c(&amp;quot;almond&amp;quot;, &amp;quot;\\w*nut&amp;quot;, &amp;quot;pecan&amp;quot;)

df %&amp;gt;%
  mutate(ingredient = case_when(str_detect(.$description, &amp;quot;butter&amp;quot;) ~  &amp;quot;butter&amp;quot;,
                                str_detect(.$description, &amp;quot;milk&amp;quot;)   ~  &amp;quot;milk&amp;quot;,
                                str_detect(.$description, &amp;quot;sugar&amp;quot;)  ~  &amp;quot;sugar&amp;quot;,
                                str_detect(.$description, &amp;quot;salt&amp;quot;)   ~  &amp;quot;salt&amp;quot;,
                                str_detect_any(.$description, nuts) ~  &amp;quot;nut&amp;quot;,
                                TRUE                                ~  as.character(NA)
                                )
         )&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## # A tibble: 7 x 2
##   description                                                   ingredient
##   &amp;lt;chr&amp;gt;                                                         &amp;lt;chr&amp;gt;     
## 1 1/2 cup unsalted, organic, non-GMO, gluten-free, single-orig… butter    
## 2 1 cup buttermilk                                              butter    
## 3 4 cups sugar                                                  sugar     
## 4 4 cups slivered almonds                                       nut       
## 5 1/2 cup chopped walnuts                                       nut       
## 6 1 teaspoon salt                                               salt      
## 7 25 blueberries                                                &amp;lt;NA&amp;gt;&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;The way &lt;code&gt;case_when()&lt;/code&gt; works is just like a bunch of nested &lt;code&gt;ifelse()&lt;/code&gt; statements. That is, if it satisfies a condition on the left of the &lt;code&gt;~&lt;/code&gt; in the first line, it returns the output to the right, otherwise it goes to the next line. That results in “buttermilk” getting categorized as “butter”. If you wanted it to be captured as “milk” instead, you could switch the order of the butter and milk lines inside &lt;code&gt;case_when()&lt;/code&gt;.&lt;/p&gt;
&lt;p&gt;I had to do this sort of thing &lt;strong&gt;a lot&lt;/strong&gt;. For example, when “creamy peanut butter” was getting categorized as “cream” or “butter” instead of “nuts” or when “unsalted butter” was getting categorized as “salt”. You’ll also notice that if a description makes it all the way through the list, it gets categorized as &lt;code&gt;NA&lt;/code&gt;. I’ll never be able to categorize all the cupcake/muffin ingredients, because people put &lt;a href=&#34;https://www.allrecipes.com/recipe/215561/peanut-butter-bacon-cupcake/&#34;&gt;weird shit&lt;/a&gt; in their baked goods.&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id=&#34;conclusion&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;Conclusion&lt;/h1&gt;
&lt;p&gt;Webscraping can be frustrating, but you can set yourself up for success by choosing an easily scrapable website, annotating your code as you go, and taking measures to make your code as readable as possible. With big, messy data, you’ll likely never get it perfect, but you can use random samples of websites to help debug your code and test its effectiveness on new random samples of websites.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;next-steps&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;Next Steps&lt;/h1&gt;
&lt;p&gt;Now that I have a data set I’m pretty happy with, the next step of the project is to do some exploratory data analysis to see what properties it has that are relevant to the sorts of multivariate data that ecologists deal with. Then on to statistical analyses to figure out what ingredients make cupcakes different from muffins. Is it sweetness? Is it something to do with leavening? Butter vs oil? Leave your predictions in the comments below!&lt;/p&gt;
&lt;/div&gt;
</description>
    </item>
    
  </channel>
</rss>
